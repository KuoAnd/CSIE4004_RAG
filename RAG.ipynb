{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ABdvz6S7fh"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TnVFS-cFCfc0",
        "outputId": "0a4912d8-419f-44ef-e345-d864ac03aa7c"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-gemini llama-index-embeddings-gemini #llama-index-embeddings-openai\n",
        "!pip install tqdm\n",
        "\n",
        "!pip install langchain-google-genai\n",
        "!pip install --upgrade langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install faiss-cpu\n",
        "\n",
        "!pip install gradio\n",
        "\n",
        "!pip install pymuPDF\n",
        "\n",
        "!pip install wordcloud matplotlib jieba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isjc6I_7CNhJ",
        "outputId": "550962c8-de04-4b89-cb32-12b640d1e7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "GEMINI_API = \"YOUR_GEMINI_API_KEY\"\n",
        "\n",
        "import os\n",
        "# 若要避免 GCE Metadata Issue，可以設定 GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API\n",
        "\n",
        "save_folder = '/content/drive/MyDrive/RAG/'\n",
        "audio_folder = save_folder + 'voice/'\n",
        "save_text_folder = save_folder + 'text/'\n",
        "\n",
        "caption_folder = '/content/caption/'\n",
        "text_folder = '/content/text/'\n",
        "summary_folder = '/content/summary/'\n",
        "font_path = '/content/drive/MyDrive/RAG/font/NotoSansCJK-Regular.ttc'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbCiLGg2bs0f"
      },
      "source": [
        "# Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bBnW8o0fCS-E",
        "outputId": "97785e79-0503-4975-b7e7-89de2d7cecaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-c00734495571>:8: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  Gemini_model = Gemini(\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "Gemini_model = Gemini(\n",
        "    api_key=GEMINI_API,\n",
        "    model_name=\"models/gemini-2.0-flash\",\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "model_size = \"base\"\n",
        "model = whisper.load_model(model_size)\n",
        "\n",
        "def speech_to_text(audio_path, model):\n",
        "    \"\"\"使用 Whisper 模型將音檔轉成文字\"\"\"\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def get_audio_lists():\n",
        "    \"\"\"取得已處理/未處理音檔清單\"\"\"\n",
        "    audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.mp3')]\n",
        "    audio_files.sort()\n",
        "\n",
        "    processed_list = []\n",
        "    unprocessed_list = []\n",
        "    for audio_file in audio_files:\n",
        "        base_name, _ = os.path.splitext(audio_file)\n",
        "        txt_file = base_name + '.txt'\n",
        "        txt_path = os.path.join(text_folder, txt_file)\n",
        "        if os.path.exists(txt_path):\n",
        "            processed_list.append(audio_file)\n",
        "        else:\n",
        "            unprocessed_list.append(audio_file)\n",
        "    return processed_list, unprocessed_list\n",
        "\n",
        "def generate_html_list(items, empty_text=\"目前沒有資料\"):\n",
        "    \"\"\"將清單 items 轉換成 <ul><li>...</li></ul> 的 HTML\"\"\"\n",
        "    if not items:\n",
        "        return \"目前沒有處理完成的音檔\"\n",
        "    html_str = \"<ul>\"\n",
        "    for it in items:\n",
        "        html_str += f\"<li>{it}</li>\"\n",
        "    html_str += \"</ul>\"\n",
        "    return html_str\n",
        "\n",
        "# Whisper -> Gemini 修復的 Prompt\n",
        "prompt_prefix = \"\"\"\n",
        "以下是一篇語音轉文字的逐字稿，許多地方出現辨識錯誤。\n",
        "請根據你的理解，適當的替換掉詞彙，修復這篇逐字稿。\n",
        "請達成以下兩點要求：\n",
        "1. 使用繁體中文與英文，避免使用簡體中文。\n",
        "2. 加上逗號和句號，並且在適當的地方分段，每段之間用一個空行隔開。\n",
        "\n",
        "以下為逐字稿：\n",
        "\"\"\"\n",
        "\n",
        "def upload_audio(file):\n",
        "    \"\"\"將使用者上傳的音檔存到 audio_folder\"\"\"\n",
        "    if file is None:\n",
        "        return \"⚠️ 沒有可上傳的檔案！\"\n",
        "\n",
        "    if isinstance(file, dict):\n",
        "        filename = file.get('orig_name') or file.get('name')\n",
        "        if not filename:\n",
        "            filename = \"uploaded_audio.mp3\"\n",
        "        dst_path = os.path.join(audio_folder, filename)\n",
        "        with open(dst_path, 'wb') as f:\n",
        "            f.write(file['data'])\n",
        "        return f\"✅ 已上傳音檔：{filename}\"\n",
        "    else:\n",
        "        filename = os.path.basename(file.name)\n",
        "        dst_path = os.path.join(audio_folder, filename)\n",
        "        shutil.copyfile(file.name, dst_path)\n",
        "        return f\"✅ 已上傳音檔：{filename}\"\n",
        "\n",
        "def convert_selected_audio(selected_files):\n",
        "    \"\"\"\n",
        "    透過 generator (yield) 提供動態進度回饋：\n",
        "      - 每處理一個音檔，就即時告知前端「目前處理第幾個 / 總共多少」。\n",
        "      - 完成後再顯示最終訊息。\n",
        "    \"\"\"\n",
        "    if not selected_files:\n",
        "        # 第一次 yield 就回傳錯誤訊息並結束\n",
        "        yield (\"⚠️ 請至少勾選一個音檔！\", generate_html_list([]), [])\n",
        "        return\n",
        "\n",
        "    total = len(selected_files)\n",
        "    converted_count = 0\n",
        "\n",
        "    # 這行只是後台終端顯示用，不會影響 Gradio 介面\n",
        "    for idx, audio_file in enumerate(tqdm(selected_files, desc=\"Converting files\", leave=False), start=1):\n",
        "        # 前端介面更新：目前正處理第 idx/total 個檔案\n",
        "        yield (f\"正在處理：{audio_file} ({idx}/{total})\", generate_html_list([]), [])\n",
        "\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        if not os.path.exists(audio_path):\n",
        "            continue\n",
        "\n",
        "        base_name, _ = os.path.splitext(audio_file)\n",
        "\n",
        "        # (1) Whisper => 產生「語音逐字稿」raw_caption\n",
        "        raw_caption = speech_to_text(audio_path, model)\n",
        "\n",
        "        # (2) 儲存逐字稿到 caption_folder\n",
        "        caption_filename = base_name + '.txt'\n",
        "        caption_path = os.path.join(caption_folder, caption_filename)\n",
        "        with open(caption_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(raw_caption)\n",
        "\n",
        "        # (3) 呼叫 Gemini 修復\n",
        "        prompt_text = prompt_prefix + raw_caption\n",
        "        fixed_caption = Gemini_model.complete(prompt_text).text\n",
        "\n",
        "        # (4) 儲存修復後文字到 text_folder\n",
        "        text_filename = base_name + '.txt'\n",
        "        text_path = os.path.join(text_folder, text_filename)\n",
        "        with open(text_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(fixed_caption)\n",
        "\n",
        "        converted_count += 1\n",
        "        # 可以做輕量暫停，讓前端有機會捕捉更新\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # 所有音檔處理完後，更新介面顯示最終結果\n",
        "    processed, unprocessed = get_audio_lists()\n",
        "    processed_html = generate_html_list(processed)\n",
        "    yield (f\"✅ 已成功轉換 {converted_count} 個音檔！\", processed_html, unprocessed)\n",
        "\n",
        "def refresh_audio():\n",
        "    \"\"\"重新整理 Audio 分頁\"\"\"\n",
        "    processed, unprocessed = get_audio_lists()\n",
        "    processed_html = generate_html_list(processed)\n",
        "    return processed_html, gr.update(choices=unprocessed, value=[]), None, \"\", \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXOy9I_8m01Q"
      },
      "source": [
        "# Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snr0HIkoCWQ4"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "import fitz  # PyMuPDF for PDF parsing\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "vector_db = None\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    \"\"\"使用 PyMuPDF 解析 PDF 內容\"\"\"\n",
        "    text = \"\"\n",
        "    with fitz.open(file_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def get_text_files():\n",
        "    # 同時列出 .txt 與 .pdf 檔案\n",
        "    return [f for f in sorted(os.listdir(text_folder)) if f.endswith('.txt') or f.endswith('.pdf')]\n",
        "\n",
        "\n",
        "def upload_text_file(file):\n",
        "    \"\"\"\n",
        "    上傳 .txt/.pdf 到 text_folder，並回傳訊息 & 更新 CheckBoxGroup 列表\n",
        "    支援多檔案上傳 (file_count=\"multiple\")\n",
        "    \"\"\"\n",
        "    if file is None:\n",
        "        return \"⚠️ 沒有檔案可以上傳！\", []\n",
        "\n",
        "    filenames = []\n",
        "    if isinstance(file, list):\n",
        "        files = file\n",
        "    else:\n",
        "        files = [file]\n",
        "\n",
        "    for f in files:\n",
        "        if isinstance(f, dict):\n",
        "            fname = f.get('orig_name') or f.get('name')\n",
        "            if not fname:\n",
        "                fname = \"uploaded_file.txt\"\n",
        "            dst_path = os.path.join(text_folder, fname)\n",
        "            with open(dst_path, 'wb') as out:\n",
        "                out.write(f['data'])\n",
        "            filenames.append(fname)\n",
        "        else:\n",
        "            fname = os.path.basename(f.name)\n",
        "            dst_path = os.path.join(text_folder, fname)\n",
        "            shutil.copyfile(f.name, dst_path)\n",
        "            filenames.append(fname)\n",
        "\n",
        "    updated_txt_files = get_text_files()\n",
        "    msg = f\"✅ 已上傳 {len(filenames)} 個檔案: {', '.join(filenames)}\"\n",
        "    return msg, updated_txt_files\n",
        "\n",
        "def process_files(uploaded_files, selected_files):\n",
        "    \"\"\"\n",
        "    將「勾選」+「剛上傳」的文件整合，切 chunk 後建立 FAISS 向量資料庫\n",
        "    並回傳： (處理結果: str, 文字檔案清單: HTML, 文字檔案清單: HTML)\n",
        "      - 第2 & 第3 個輸出分別要顯示在 Text 與 Chat 分頁\n",
        "    \"\"\"\n",
        "    global vector_db\n",
        "    docs = []\n",
        "    used_files = []  # 用來記錄本次建立資料庫使用的檔案\n",
        "\n",
        "    # 1) 處理勾選檔案\n",
        "    if selected_files:\n",
        "        for filename in selected_files:\n",
        "            file_path = os.path.join(text_folder, filename)\n",
        "            used_files.append(filename)  # 記錄\n",
        "            if filename.endswith(\".txt\"):\n",
        "                loader = TextLoader(file_path, encoding='utf-8')\n",
        "                documents = loader.load()\n",
        "                docs.extend(documents)\n",
        "            elif filename.endswith(\".pdf\"):\n",
        "                pdf_text = extract_text_from_pdf(file_path)\n",
        "                doc = Document(page_content=pdf_text, metadata={\"source\": file_path})\n",
        "                docs.append(doc)\n",
        "\n",
        "    # 2) 處理剛上傳的檔案\n",
        "    uploaded_count = 0\n",
        "    if uploaded_files:\n",
        "        if isinstance(uploaded_files, dict) or hasattr(uploaded_files, 'name'):\n",
        "            uploaded_files = [uploaded_files]\n",
        "\n",
        "        for f in uploaded_files:\n",
        "            if isinstance(f, dict):\n",
        "                up_name = f.get('orig_name') or f.get('name')\n",
        "            else:\n",
        "                up_name = os.path.basename(f.name)\n",
        "\n",
        "            used_files.append(up_name)\n",
        "\n",
        "            if up_name.endswith(\".txt\"):\n",
        "                loader = TextLoader(os.path.join(text_folder, up_name), encoding='utf-8')\n",
        "                documents = loader.load()\n",
        "                docs.extend(documents)\n",
        "                uploaded_count += 1\n",
        "            elif up_name.endswith(\".pdf\"):\n",
        "                pdf_text = extract_text_from_pdf(os.path.join(text_folder, up_name))\n",
        "                doc = Document(page_content=pdf_text, metadata={\"source\": up_name})\n",
        "                docs.append(doc)\n",
        "                uploaded_count += 1\n",
        "            else:\n",
        "                return f\"⚠️ 不支援的檔案格式: {up_name}\", \"\", \"\"\n",
        "\n",
        "    if not docs:\n",
        "        return \"⚠️ 沒有可用文件，請至少勾選或上傳 .txt / .pdf 文件\", \"\", \"\"\n",
        "\n",
        "    # 3) 建立向量資料庫\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    vector_db = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "    total_count = (len(selected_files) if selected_files else 0) + uploaded_count\n",
        "    result_msg = f\"✅ 已成功處理 {total_count} 個文件並建立向量資料庫！\"\n",
        "\n",
        "    # 用 HTML 條列式呈現\n",
        "    info_html = \"<p>本次向量資料庫使用的檔案：</p>\" + generate_html_list(used_files, \"（無）\")\n",
        "\n",
        "    # 同一個 HTML 分別給「Text 分頁」與「Chat 分頁」顯示\n",
        "    return result_msg, info_html, info_html\n",
        "\n",
        "def refresh_text_tab():\n",
        "    \"\"\"\n",
        "    重新整理 Text 分頁：\n",
        "      - 清空上傳檔案\n",
        "      - 清空上傳結果\n",
        "      - 清空處理結果\n",
        "      - 清空保存結果\n",
        "      - 清空「資料庫資訊」\n",
        "      - 更新 CheckBoxGroup\n",
        "    \"\"\"\n",
        "    txt_files = get_text_files()\n",
        "    return gr.update(choices=txt_files, value=[]), None, \"\", \"\", \"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def save_text_files():\n",
        "    \"\"\"\n",
        "    將 ./text_folder 裡的所有檔案複製到使用者指定的雲端路徑 (save_path + '/text_folder')\n",
        "    並回傳一個提示訊息\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(text_folder):\n",
        "        return \"⚠️ 本機 text_folder 不存在，沒有可保存的檔案。\"\n",
        "\n",
        "    # 建立雲端的資料夾 (如果不存在)\n",
        "    os.makedirs(save_text_folder, exist_ok=True)\n",
        "\n",
        "    # 逐檔複製\n",
        "    for filename in os.listdir(text_folder):\n",
        "        source_file = os.path.join(text_folder, filename)\n",
        "        target_file = os.path.join(save_text_folder, filename)\n",
        "\n",
        "        if os.path.isfile(source_file):\n",
        "            shutil.copyfile(source_file, target_file)\n",
        "\n",
        "    return f\"✅ 已成功將 {text_folder} 裡的所有檔案，複製到 {save_text_folder}。\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ytgLVYTTMvc"
      },
      "source": [
        "# Summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdQOxftMCYPA"
      },
      "outputs": [],
      "source": [
        "summarize_prompt = \"\\n請幫我總結以上內容，列出最重要的要點與關鍵資訊。請使用條列式重點，並維持在 200 字以內。\"\n",
        "os.makedirs(summary_folder, exist_ok=True)\n",
        "\n",
        "def summarize_file(selected_file):\n",
        "    \"\"\"\n",
        "    選擇一個 text_folder 中的檔案，Gemini 生成摘要 (Markdown)，\n",
        "    同時存入 summary_folder\n",
        "    \"\"\"\n",
        "    if not selected_file:\n",
        "        return \"⚠️ 請先選擇一個檔案！\", \"\"\n",
        "\n",
        "    text_path = os.path.join(text_folder, selected_file)\n",
        "    if not os.path.exists(text_path):\n",
        "        return \"⚠️ 找不到檔案，請重新整理！\", \"\"\n",
        "\n",
        "    # 讀取檔案內容\n",
        "    with open(text_path, 'r', encoding='utf-8') as f:\n",
        "        text_content = f.read()\n",
        "\n",
        "    # 呼叫 Gemini 產生摘要 (Markdown)\n",
        "    summary = Gemini_model.complete(text_content + summarize_prompt).text\n",
        "\n",
        "    # 存檔\n",
        "    base_name, _ = os.path.splitext(selected_file)\n",
        "    summary_filename = base_name + \"_summary.txt\"\n",
        "    summary_path = os.path.join(summary_folder, summary_filename)\n",
        "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    return f\"✅ 已成功為「{selected_file}」生成摘要，並存入 {summary_filename}\", summary\n",
        "\n",
        "def refresh_summary_tab():\n",
        "    \"\"\"重新整理 Summary 分頁\"\"\"\n",
        "    files = [f for f in sorted(os.listdir(text_folder)) if f.endswith('.txt')]\n",
        "    return gr.update(choices=files, value=None), \"\", \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvkNBqZ-TVw3"
      },
      "source": [
        "# Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vzHebjLKOy5",
        "outputId": "7b4fd43c-2271-4043-db6a-faf4da70f3b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-c14ee2237ef9>:36: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
            "  qa_chain = load_qa_chain(llm=llm, chain_type=\"stuff\", prompt=PROMPT)\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import fitz\n",
        "import datetime\n",
        "import pytz\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "# === 初始化 ===\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
        "\n",
        "# 定義 Prompt 模板\n",
        "template = \"\"\"\n",
        "## 任務說明\n",
        "請你扮演一個專業的助手，根據以下提供的文本，回答用戶的問題。\n",
        "請提供詳細、準確、有條理的回答。\n",
        "請嚴格遵守以下事項：\n",
        "1. 如果文本中找不到相關資訊，請回答不知道，不要隨意編造答案。\n",
        "2. 全程使用繁體中文，避免使用簡體中文，專有名詞可以使用英文回答。\n",
        "\n",
        "## 文本\n",
        "[文本開始]\n",
        "{context}\n",
        "[文本結束]\n",
        "\n",
        "## 用戶問答\n",
        "{chat_history}\n",
        "User: {question}\n",
        "Assistant:\n",
        "\"\"\"\n",
        "PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\", \"chat_history\"])\n",
        "qa_chain = load_qa_chain(llm=llm, chain_type=\"stuff\", prompt=PROMPT)\n",
        "\n",
        "history_log = []\n",
        "\n",
        "def format_chat_history(history):\n",
        "    formatted = \"\"\n",
        "    # 假設 history 長度為偶數，且每兩筆資料分別是 user / assistant\n",
        "    for i in range(0, len(history), 2):\n",
        "        user_msg = history[i][\"content\"]\n",
        "        assistant_msg = history[i+1][\"content\"]\n",
        "        formatted += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
        "    return formatted\n",
        "\n",
        "\n",
        "def gradio_chat(user_input, history):\n",
        "    if vector_db is None:\n",
        "        return history + [{\"role\": \"user\", \"content\": user_input},\n",
        "                          {\"role\": \"assistant\", \"content\": \"⚠️ 尚未上傳或選擇文件！\"}], history, \"\"\n",
        "\n",
        "    try:\n",
        "        docs = vector_db.similarity_search(user_input, k=3)\n",
        "        history_text = format_chat_history(history)\n",
        "        result = qa_chain.run({\n",
        "            \"input_documents\": docs,\n",
        "            \"question\": user_input,\n",
        "            \"chat_history\": history_text\n",
        "        })\n",
        "\n",
        "        tz = pytz.timezone('Asia/Taipei')\n",
        "        timestamp = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        history_log.append({\n",
        "            \"time\": timestamp,\n",
        "            \"query\": user_input,\n",
        "            \"answer\": result\n",
        "        })\n",
        "\n",
        "        history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        history.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return history, history, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # return history + [(user_input, f\"發生錯誤: {str(e)}\")], history, \"\"\n",
        "        return history + [{\"role\": \"user\", \"content\": user_input},\n",
        "                          {\"role\": \"assistant\", \"content\": f\"發生錯誤: {str(e)}\"}], history, \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us662OmyTXd0"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2CCotZ1KG2W"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import jieba.posseg as pseg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def export_history():\n",
        "    if not history_log:\n",
        "        return None, \"⚠️ 目前尚無查詢紀錄！\"\n",
        "\n",
        "    filename = \"query_history.txt\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for entry in history_log:\n",
        "            f.write(f\"Time: {entry['time']}\\n\")\n",
        "            f.write(f\"Query: {entry['query']}\\n\")\n",
        "            f.write(f\"Answer: {entry['answer']}\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    return filename, \"✅ 查詢紀錄已生成！\"\n",
        "\n",
        "# === 生成關鍵詞詞雲（僅保留名詞） ===\n",
        "def generate_keyword_cloud():\n",
        "    if not history_log:\n",
        "        return None, None, \"⚠️ 目前尚無查詢紀錄，無法生成詞雲！\"\n",
        "\n",
        "    all_answers = \" \".join([entry['answer'] for entry in history_log])\n",
        "\n",
        "    # 使用 jieba.posseg 斷詞並標註詞性\n",
        "    words = pseg.cut(all_answers)\n",
        "\n",
        "    # 選出詞性為名詞的詞\n",
        "    noun_words = [word for word, flag in words if flag.startswith('n') and len(word) > 1]\n",
        "\n",
        "    if not noun_words:\n",
        "        return None, None, \"⚠️ 沒有足夠的有效名詞生成詞雲！\"\n",
        "\n",
        "    text_for_wordcloud = \" \".join(noun_words)\n",
        "    wc = WordCloud(font_path=font_path, width=800, height=400, background_color='white')\n",
        "    wc.generate(text_for_wordcloud)\n",
        "    filename = \"keyword_cloud.png\"\n",
        "    wc.to_file(filename)\n",
        "\n",
        "    # 顯示即時圖片\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"keyword_cloud_display.png\")\n",
        "\n",
        "    return filename, \"keyword_cloud_display.png\", \"✅ 名詞詞雲已生成！\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMvdEkirb1hG"
      },
      "source": [
        "# Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tJVnlXxCZkB",
        "outputId": "b5bf6976-3ed1-44c5-a758-095843ac416d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e0145b8fff80b6a843.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e0145b8fff80b6a843.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def build_interface():\n",
        "    with gr.Blocks() as demo:\n",
        "\n",
        "        # ========== 分頁 1: Audio ==========\n",
        "        with gr.Tab(\"Audio\"):\n",
        "            gr.Markdown(\"## 語音處理\")\n",
        "\n",
        "            init_processed, init_unprocessed = get_audio_lists()\n",
        "            init_processed_html = generate_html_list(init_processed)\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "\n",
        "                    # 已處理音檔 (HTML)\n",
        "                    processed_html = gr.HTML(\n",
        "                        value=init_processed_html,\n",
        "                        label=\"已處理完成的音檔\"\n",
        "                    )\n",
        "\n",
        "                    unprocessed_checkbox = gr.CheckboxGroup(\n",
        "                        choices=init_unprocessed,\n",
        "                        label=\"尚未處理的音檔\"\n",
        "                    )\n",
        "\n",
        "                    convert_msg = gr.Label(label=\"轉換結果\")\n",
        "                    convert_btn = gr.Button(\"轉換文字\")\n",
        "                    refresh_btn = gr.Button(\"重新整理\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    audio_uploader = gr.File(\n",
        "                        label=\"上傳新的音檔\",\n",
        "                        file_types=[\"audio\"],\n",
        "                        file_count=\"single\"\n",
        "                    )\n",
        "                    upload_msg = gr.Label(label=\"上傳結果\")\n",
        "                    upload_btn = gr.Button(\"上傳\")\n",
        "\n",
        "            # 綁定\n",
        "            upload_btn.click(\n",
        "                fn=upload_audio,\n",
        "                inputs=[audio_uploader],\n",
        "                outputs=[upload_msg]\n",
        "            )\n",
        "            convert_btn.click(\n",
        "                fn=convert_selected_audio,\n",
        "                inputs=[unprocessed_checkbox],\n",
        "                outputs=[convert_msg, processed_html, unprocessed_checkbox]\n",
        "            )\n",
        "\n",
        "            refresh_btn.click(\n",
        "                fn=refresh_audio,\n",
        "                inputs=[],\n",
        "                outputs=[processed_html, unprocessed_checkbox, audio_uploader, upload_msg, convert_msg]\n",
        "            )\n",
        "\n",
        "        # ========== 分頁 2: Text ==========\n",
        "        with gr.Tab(\"Text\"):\n",
        "            gr.Markdown(\"## 文件處理\")\n",
        "\n",
        "            init_txt_pdf_files = get_text_files()\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    db_info_html_text = gr.HTML(label=\"資料庫資訊 (Text)\")  # HTML 顯示\n",
        "                    db_info_html_chat = gr.HTML(label=\"資料庫資訊 (Chat)\", visible=False)\n",
        "\n",
        "                    text_checkbox = gr.CheckboxGroup(\n",
        "                        choices=init_txt_pdf_files,\n",
        "                        label=\"選擇已有檔案\",\n",
        "                        value=[]\n",
        "                    )\n",
        "\n",
        "                    process_msg = gr.Label(label=\"處理結果\")\n",
        "                    process_btn = gr.Button(\"建立資料庫\")\n",
        "                    refresh_text_btn = gr.Button(\"重新整理\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    text_file_uploader = gr.File(\n",
        "                        label=\"上傳文件 (.txt 或 .pdf)\",\n",
        "                        file_types=[\".txt\", \".pdf\"],\n",
        "                        file_count=\"multiple\"\n",
        "                    )\n",
        "                    text_upload_msg = gr.Label(label=\"上傳結果\")\n",
        "                    upload_files_btn = gr.Button(\"上傳文件\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    save_text_msg = gr.Label(label=\"保存結果\")  # 顯示保存結果的訊息\n",
        "                    save_text_btn = gr.Button(\"保存文本\")\n",
        "\n",
        "            # 上傳\n",
        "            upload_files_btn.click(\n",
        "                fn=upload_text_file,\n",
        "                inputs=[text_file_uploader],\n",
        "                outputs=[text_upload_msg, text_checkbox]\n",
        "            )\n",
        "\n",
        "            # 重新整理\n",
        "            refresh_text_btn.click(\n",
        "                fn=refresh_text_tab,\n",
        "                inputs=[],\n",
        "                outputs=[text_checkbox, text_file_uploader, text_upload_msg, process_msg, save_text_msg]\n",
        "            )\n",
        "\n",
        "            save_text_btn.click(\n",
        "                fn=save_text_files,\n",
        "                inputs=[],   # 從這裡讀取雲端路徑\n",
        "                outputs=[save_text_msg]       # 將保存結果顯示在這個 label\n",
        "            )\n",
        "\n",
        "        # ========== 分頁 3: Summary ==========\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            gr.Markdown(\"## 生成摘要\")\n",
        "\n",
        "            # Radio 單選\n",
        "            text_files = [f for f in sorted(os.listdir(text_folder)) if f.endswith('.txt')]\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    text_radio = gr.Radio(\n",
        "                        choices=text_files,\n",
        "                        label=\"選擇要摘要的檔案\"\n",
        "                    )\n",
        "\n",
        "                    summary_btn = gr.Button(\"生成摘要\")\n",
        "                    summary_result = gr.Markdown(label=\"摘要內容\")\n",
        "                with gr.Column():\n",
        "                    summary_status = gr.Label(label=\"摘要狀態\")\n",
        "                    refresh_sum_btn = gr.Button(\"重新整理\")\n",
        "\n",
        "            summary_btn.click(\n",
        "                fn=summarize_file,\n",
        "                inputs=[text_radio],\n",
        "                outputs=[summary_status, summary_result]\n",
        "            )\n",
        "            refresh_sum_btn.click(\n",
        "                fn=refresh_summary_tab,\n",
        "                inputs=[],\n",
        "                outputs=[text_radio, summary_status, summary_result]\n",
        "            )\n",
        "\n",
        "        # ========== 分頁 4: Chat ==========\n",
        "        with gr.Tab(\"Chat\"):\n",
        "            gr.Markdown(\"## 問答對話\")\n",
        "\n",
        "            # 新增一個 HTML，用於顯示「目前建立的資料庫檔案資訊」\n",
        "            db_info_html_chat = gr.HTML(\n",
        "                value=\"尚未建立任何資料庫\",\n",
        "                label=\"資料庫資訊 (Chat)\"\n",
        "            )\n",
        "\n",
        "            chatbot = gr.Chatbot(label=\"對話紀錄\", type=\"messages\")\n",
        "            user_input = gr.Textbox(placeholder=\"請輸入您的問題...\", label=\"輸入\")\n",
        "            clear = gr.Button(\"清除對話\")\n",
        "\n",
        "            state = gr.State([])\n",
        "\n",
        "            user_input.submit(\n",
        "                fn=gradio_chat,\n",
        "                inputs=[user_input, state],\n",
        "                outputs=[chatbot, state, user_input]\n",
        "            )\n",
        "            clear.click(lambda: ([], []), None, outputs=[chatbot, state])\n",
        "\n",
        "        process_btn.click(\n",
        "            fn=process_files,\n",
        "            inputs=[text_file_uploader, text_checkbox],\n",
        "            outputs=[process_msg, db_info_html_text, db_info_html_chat],\n",
        "            queue=False\n",
        "        )\n",
        "\n",
        "        # ========== 分頁 5: Analysis ==========\n",
        "        with gr.Tab(\"Analysis\"):\n",
        "            gr.Markdown(\"## 分析工具\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    keyword_cloud_file = gr.File(label=\"下載詞雲\")\n",
        "                    keyword_msg = gr.Label(label=\"詞雲結果\")\n",
        "                    keyword_btn = gr.Button(\"生成關鍵詞詞雲\")\n",
        "                    keyword_cloud_display = gr.Image(label=\"詞雲預覽\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    download_file = gr.File(label=\"下載紀錄\")\n",
        "                    export_msg = gr.Label(label=\"匯出結果\")\n",
        "                    export_btn = gr.Button(\"匯出查詢紀錄\")\n",
        "\n",
        "            export_btn.click(export_history, outputs=[download_file, export_msg])\n",
        "            keyword_btn.click(generate_keyword_cloud, outputs=[keyword_cloud_file, keyword_cloud_display, keyword_msg])\n",
        "\n",
        "        demo.launch(debug=True)\n",
        "\n",
        "# 建立必要資料夾 & 執行\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "os.makedirs(save_text_folder, exist_ok=True)\n",
        "os.makedirs(caption_folder, exist_ok=True)\n",
        "os.makedirs(text_folder, exist_ok=True)\n",
        "os.makedirs(summary_folder, exist_ok=True)\n",
        "\n",
        "if os.path.exists(save_text_folder):\n",
        "    for filename in os.listdir(save_text_folder):\n",
        "        src_file = os.path.join(save_text_folder, filename)\n",
        "        dst_file = os.path.join(text_folder, filename)\n",
        "\n",
        "        # 僅複製檔案 (檔名)，子資料夾不處理\n",
        "        if os.path.isfile(src_file):\n",
        "            # 若目標檔案已存在，就跳過\n",
        "            if not os.path.exists(dst_file):\n",
        "                shutil.copyfile(src_file, dst_file)\n",
        "\n",
        "build_interface()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
